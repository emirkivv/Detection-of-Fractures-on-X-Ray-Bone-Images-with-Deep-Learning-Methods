# -*- coding: utf-8 -*-
"""RT-DETR-X

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IdKE-4dbSkFlaTEaNhpO-_29vxmiS8SF
"""

!pip install ultralytics

import os
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import cv2
import random
import matplotlib.image as mpimg
import warnings
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.preprocessing.image import ImageDataGenerator
warnings.filterwarnings('ignore')

from keras.models import Sequential
from keras.layers import *
from keras.callbacks import EarlyStopping , ReduceLROnPlateau
from sklearn.metrics import classification_report, confusion_matrix, f1_score
from sklearn.utils import class_weight
from tensorflow.keras.applications import DenseNet121
from keras import backend as keras
from ultralytics import RTDETR
from tensorflow.keras.preprocessing.image import load_img, img_to_array

import locale
def getpreferredencoding(do_setlocale = True):
    return "UTF-8"
locale.getpreferredencoding = getpreferredencoding

import os

os.environ['KAGGLE_USERNAME'] = 'username'
os.environ['KAGGLE_KEY'] = 'key'

!pip install kaggle

!kaggle datasets download emirkiv/fracture-detection-ekiha-final
!unzip fracture-detection-ekiha-final.zip > /dev/null

import os
train_images = '/content/dataset_final/4_dataset_aug_mixed/train/images'
train_labels = '/content/dataset_final/4_dataset_aug_mixed/train/labels'

test_images = '/content/dataset_final/4_dataset_aug_mixed/test/images'
test_labels = '/content/dataset_final/4_dataset_aug_mixed/test/labels'

val_images = '/content/dataset_final/4_dataset_aug_mixed/valid/images'
val_labels = '/content/dataset_final/4_dataset_aug_mixed/valid/labels'

print('Number of train images: ' + str(len(os.listdir(train_images))))
print('Number of train labels: ' + str(len(os.listdir(train_labels))))
print('Number of val images: ' + str(len(os.listdir(val_images))))
print('Number of val labels: ' + str(len(os.listdir(val_labels))))
print('Number of test images: ' + str(len(os.listdir(test_images))))
print('Number of test labels: ' + str(len(os.listdir(test_labels))))
print('Total images: ' + str(len(os.listdir(train_images)) + len(os.listdir(test_images)) + len(os.listdir(val_images))))

import matplotlib.pyplot as plt
# Get a list of all the image files in the training images directory
image_files = os.listdir(train_images)

# Choose 9 random image files from the list
random_images = random.sample(image_files, 9)

# Set up the plot
fig, axs = plt.subplots(3, 3, figsize=(9, 9))

# Loop over the random images and plot the object detections
for i, image_file in enumerate(random_images):
    row = i // 3
    col = i % 3

    # Load the image
    image_path = os.path.join(train_images, image_file)
    image = cv2.imread(image_path)

    # Load the labels for this image
    label_file = os.path.splitext(image_file)[0] + ".txt"
    label_path = os.path.join(train_labels, label_file)
    with open(label_path, "r") as f:
        labels = f.read().strip().split("\n")

    # Loop over the labels and plot the object detections
    # Loop over the labels and plot the object detections
    for label in labels:
        if len(label.split()) != 5:
            continue
        class_id, x_center, y_center, width, height = map(float, label.split())
        x_min = int((x_center - width/2) * image.shape[1])
        y_min = int((y_center - height/2) * image.shape[0])
        x_max = int((x_center + width/2) * image.shape[1])
        y_max = int((y_center + height/2) * image.shape[0])
        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 0), 3)


    # Show the image with the object detections
    axs[row, col].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    axs[row, col].axis('off')

plt.show()

import os
import shutil
import random
import os
import cv2
import numpy as np
import albumentations as A
from albumentations.core.bbox_utils import convert_bboxes_to_albumentations, convert_bboxes_from_albumentations
import os
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import cv2
import random
import matplotlib.image as mpimg
import warnings
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.preprocessing.image import ImageDataGenerator
warnings.filterwarnings('ignore')
from keras.models import Sequential
from keras.layers import *
from keras.callbacks import EarlyStopping , ReduceLROnPlateau
from sklearn.metrics import classification_report, confusion_matrix, f1_score
from sklearn.utils import class_weight
from tensorflow.keras.applications import DenseNet121
from keras import backend as keras
from ultralytics import YOLO
from tensorflow.keras.preprocessing.image import load_img, img_to_array

from ultralytics import RTDETR

# Loading a pretrained model
model = RTDETR('rtdetr-x.pt')

# Training the model
model.train(data = '/content/dataset_final/4_dataset_aug_mixed/data.yaml',
            epochs = 100,
            imgsz = 768,
            seed = 35,
            patience = 300,
            amp = False,


            lr0=0.001,    # Initial learning rate ben ekledim
            batch=16,     # Batch size ben ekledim bunları(ibo)
            freeze=10,    # Fine tuning
            warmup_epochs=5, # Fine tuning


            dropout=0.05, # Random dropout
            iou=0.3, # Training IoU threshold
            optimizer="SGD"
)

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
# %matplotlib inline
# Reading the results image file
img = mpimg.imread('/content/runs/detect/train/results.png')

# Plotting the confusion matrix image
fig, ax = plt.subplots(figsize = (15, 15))

ax.imshow(img)
ax.axis('off');

# Loading the best performing model
model = RTDETR('/content/runs/detect/train/weights/last.pt')

# Evaluating the model on the test dataset
metrics = model.val(conf = 0.2, split = 'test')

def ship_detect_with_labels(img_path, label_path):
    img = cv2.imread(img_path)
    if img is None:
        print(f"⚠️ Görsel yüklenemedi: {img_path}")
        return

    if not os.path.exists(label_path):
        print(f"⚠️ Etiket dosyası yok: {label_path}")
        return

    with open(label_path, "r") as f:
        labels = f.read().strip().split("\n")

    img_with_labels = img.copy()
    for label in labels:
        if len(label.split()) != 5:
            continue
        class_id, x_center, y_center, width, height = map(float, label.split())
        x_min = int((x_center - width / 2) * img.shape[1])
        y_min = int((y_center - height / 2) * img.shape[0])
        x_max = int((x_center + width / 2) * img.shape[1])
        y_max = int((y_center + height / 2) * img.shape[0])
        cv2.rectangle(img_with_labels, (x_min, y_min), (x_max, y_max), (255, 0, 0), 2)

    detect_result = model(img)
    detect_img = detect_result[0].plot()

    fig, axs = plt.subplots(1, 2, figsize=(15, 7))
    axs[0].imshow(cv2.cvtColor(img_with_labels, cv2.COLOR_BGR2RGB))
    axs[0].set_title("Original Image with Labels")
    axs[0].axis('off')

    axs[1].imshow(detect_img)
    axs[1].set_title("Model Detection Output")
    axs[1].axis('off')

    plt.suptitle(f"Image: {os.path.basename(img_path)}", fontsize=14)
    plt.tight_layout()
    plt.show()

import os

# Görsellerin bulunduğu klasör yollarını belirt
# test_images = "..."
# test_labels = "..."

image_files = [f for f in os.listdir(test_images) if f.endswith('.jpg') or f.endswith('.png')]

for img_file in image_files:
    img_path = os.path.join(test_images, img_file)
    label_path = os.path.join(test_labels, os.path.splitext(img_file)[0] + ".txt")

    ship_detect_with_labels(img_path, label_path)

import seaborn as sns
# Loading the best performing model
model = RTDETR('/content/content/runs/detect/train/weights/last.pt')

# Evaluating the model on the test dataset
metrics = model.val(conf = 0.2, split = 'test',)

# Create the barplot
ax = sns.barplot(x=['mAP50-95', 'mAP50', 'mAP75'], y=[metrics.box.map, metrics.box.map50, metrics.box.map75])

# Set the title and axis labels
ax.set_title('RT-DETR Evaluation Metrics')
ax.set_xlabel('Metric')
ax.set_ylabel('Value')

# Set the figure size
fig = plt.gcf()
fig.set_size_inches(8, 6)

# Add the values on top of the bars
for p in ax.patches:
    ax.annotate('{:.3f}'.format(p.get_height()), (p.get_x() + p.get_width() / 2, p.get_height()), ha='center', va='bottom')

# Show the plot
plt.show()

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
# Reading the confusion matrix image file
img = mpimg.imread('/content/runs/detect/val2/confusion_matrix.png')

# Plotting the confusion matrix image
fig, ax = plt.subplots(figsize = (15, 15))

ax.imshow(img)
ax.axis('off');